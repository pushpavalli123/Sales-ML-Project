"""
Retail Sales Machine Learning Models
Sales Prediction, Customer Segmentation, and Profit Analysis
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
import os
import pickle

# Machine Learning imports
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.tree import DecisionTreeClassifier
from sklearn.cluster import KMeans
from sklearn.metrics import (mean_squared_error, mean_absolute_error, r2_score,
                            silhouette_score, classification_report, confusion_matrix)

warnings.filterwarnings('ignore')

# Set visualization style
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['figure.figsize'] = (12, 6)

# Color palette
COLORS = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#3B1F2B', '#44AF69']

print("=" * 70)
print("       RETAIL SALES - MACHINE LEARNING MODELS")
print("=" * 70)

# ============================================================
# LOAD AND PREPARE DATA
# ============================================================
print("\nğŸ“‚ Loading Data...")

script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(script_dir)
data_path = os.path.join(project_root, '3_Power_BI', 'cleaned_sales_data.csv')

df = pd.read_csv(data_path)
df['order_date'] = pd.to_datetime(df['order_date'])
df['ship_date'] = pd.to_datetime(df['ship_date'])

print(f"   âœ“ Loaded {len(df)} records")

# ============================================================
# MODEL 1: SALES PREDICTION (Regression)
# ============================================================
print("\n" + "=" * 70)
print("ğŸ¯ MODEL 1: SALES PREDICTION (Regression)")
print("=" * 70)

# Feature Engineering for Sales Prediction
print("\nğŸ“Š Feature Engineering...")

# Create feature dataframe
sales_features = df.copy()

# Encode categorical variables
le_category = LabelEncoder()
le_segment = LabelEncoder()
le_region = LabelEncoder()
le_ship_mode = LabelEncoder()
le_sub_category = LabelEncoder()

sales_features['category_encoded'] = le_category.fit_transform(sales_features['category'])
sales_features['segment_encoded'] = le_segment.fit_transform(sales_features['segment'])
sales_features['region_encoded'] = le_region.fit_transform(sales_features['region'])
sales_features['ship_mode_encoded'] = le_ship_mode.fit_transform(sales_features['ship_mode'])
sales_features['sub_category_encoded'] = le_sub_category.fit_transform(sales_features['sub_category'])

# Select features for prediction
feature_cols = ['quantity', 'unit_price', 'discount', 'shipping_cost',
                'category_encoded', 'segment_encoded', 'region_encoded',
                'ship_mode_encoded', 'sub_category_encoded', 'month', 'quarter']

X = sales_features[feature_cols]
y = sales_features['sales']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"   âœ“ Training set: {len(X_train)} samples")
print(f"   âœ“ Test set: {len(X_test)} samples")

# Train multiple models
print("\nğŸ”§ Training Regression Models...")

models = {
    'Linear Regression': LinearRegression(),
    'Ridge Regression': Ridge(alpha=1.0),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)
}

results = {}
best_model = None
best_r2 = -np.inf

for name, model in models.items():
    print(f"\n   Training {name}...")
    
    # Use scaled data for linear models, original for tree-based
    if 'Random Forest' in name or 'Gradient Boosting' in name:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
    else:
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
    
    # Calculate metrics
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    results[name] = {
        'RMSE': rmse,
        'MAE': mae,
        'RÂ²': r2,
        'model': model,
        'predictions': y_pred
    }
    
    if r2 > best_r2:
        best_r2 = r2
        best_model = name
    
    print(f"      RMSE: ${rmse:,.2f} | MAE: ${mae:,.2f} | RÂ²: {r2:.4f}")

print(f"\nğŸ† Best Model: {best_model} (RÂ² = {best_r2:.4f})")

# Model Comparison Visualization
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# RÂ² Comparison
model_names = list(results.keys())
r2_scores = [results[m]['RÂ²'] for m in model_names]
colors = [COLORS[0] if m != best_model else COLORS[3] for m in model_names]
axes[0].barh(model_names, r2_scores, color=colors)
axes[0].set_xlabel('RÂ² Score')
axes[0].set_title('Model Comparison: RÂ² Score', fontweight='bold')
axes[0].set_xlim(0, 1)
for i, v in enumerate(r2_scores):
    axes[0].text(v + 0.02, i, f'{v:.4f}', va='center', fontweight='bold')

# Actual vs Predicted for best model
best_predictions = results[best_model]['predictions']
axes[1].scatter(y_test, best_predictions, alpha=0.5, color=COLORS[0])
axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
             'r--', linewidth=2, label='Perfect Prediction')
axes[1].set_xlabel('Actual Sales ($)')
axes[1].set_ylabel('Predicted Sales ($)')
axes[1].set_title(f'{best_model}: Actual vs Predicted', fontweight='bold')
axes[1].legend()

plt.tight_layout()
plt.savefig(os.path.join(script_dir, 'ml_sales_prediction.png'), dpi=300, bbox_inches='tight')
plt.close()
print("\n   âœ“ Saved: ml_sales_prediction.png")

# Feature Importance (Random Forest)
rf_model = results['Random Forest']['model']
feature_importance = pd.DataFrame({
    'Feature': feature_cols,
    'Importance': rf_model.feature_importances_
}).sort_values('Importance', ascending=True)

fig, ax = plt.subplots(figsize=(10, 6))
ax.barh(feature_importance['Feature'], feature_importance['Importance'], color=COLORS[1])
ax.set_xlabel('Importance Score')
ax.set_title('Feature Importance (Random Forest)', fontweight='bold')
plt.tight_layout()
plt.savefig(os.path.join(script_dir, 'ml_feature_importance.png'), dpi=300, bbox_inches='tight')
plt.close()
print("   âœ“ Saved: ml_feature_importance.png")

# ============================================================
# MODEL 2: CUSTOMER SEGMENTATION (K-Means Clustering)
# ============================================================
print("\n" + "=" * 70)
print("ğŸ‘¥ MODEL 2: CUSTOMER SEGMENTATION (RFM Analysis + K-Means)")
print("=" * 70)

# RFM Analysis
print("\nğŸ“Š Calculating RFM Metrics...")

# Reference date (last date in dataset + 1 day)
reference_date = df['order_date'].max() + pd.Timedelta(days=1)

# Calculate RFM metrics
rfm = df.groupby('customer_id').agg({
    'order_date': lambda x: (reference_date - x.max()).days,  # Recency
    'order_id': 'count',  # Frequency
    'sales': 'sum'  # Monetary
}).reset_index()

rfm.columns = ['customer_id', 'recency', 'frequency', 'monetary']

# Add customer names
customer_names = df[['customer_id', 'customer_name']].drop_duplicates()
rfm = rfm.merge(customer_names, on='customer_id')

print(f"\n   RFM Summary:")
print(rfm[['recency', 'frequency', 'monetary']].describe().round(2))

# Standardize RFM values
scaler_rfm = StandardScaler()
rfm_scaled = scaler_rfm.fit_transform(rfm[['recency', 'frequency', 'monetary']])

# Find optimal K using Elbow Method
print("\nğŸ”§ Finding Optimal Number of Clusters...")
inertias = []
silhouette_scores = []
K_range = range(2, 11)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(rfm_scaled)
    inertias.append(kmeans.inertia_)
    silhouette_scores.append(silhouette_score(rfm_scaled, kmeans.labels_))

# Optimal K based on silhouette score
optimal_k = K_range[np.argmax(silhouette_scores)]
print(f"   âœ“ Optimal K: {optimal_k} (Silhouette Score: {max(silhouette_scores):.4f})")

# Train final model with optimal K
kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
rfm['cluster'] = kmeans_final.fit_predict(rfm_scaled)

# Analyze clusters
print("\nğŸ“Š Cluster Analysis:")
cluster_analysis = rfm.groupby('cluster').agg({
    'recency': 'mean',
    'frequency': 'mean',
    'monetary': 'mean',
    'customer_id': 'count'
}).rename(columns={'customer_id': 'count'})

# Assign segment names based on RFM values
segment_names = {}
for cluster in cluster_analysis.index:
    r = cluster_analysis.loc[cluster, 'recency']
    f = cluster_analysis.loc[cluster, 'frequency']
    m = cluster_analysis.loc[cluster, 'monetary']
    
    if r < cluster_analysis['recency'].median() and m > cluster_analysis['monetary'].median():
        segment_names[cluster] = 'Champions'
    elif r < cluster_analysis['recency'].median() and f > cluster_analysis['frequency'].median():
        segment_names[cluster] = 'Loyal Customers'
    elif r > cluster_analysis['recency'].median() and m > cluster_analysis['monetary'].median():
        segment_names[cluster] = 'At Risk'
    elif r > cluster_analysis['recency'].median():
        segment_names[cluster] = 'Need Attention'
    else:
        segment_names[cluster] = 'Potential Loyalists'

rfm['segment_name'] = rfm['cluster'].map(segment_names)
cluster_analysis['segment'] = cluster_analysis.index.map(segment_names)

print(cluster_analysis.round(2))

# Visualizations
fig, axes = plt.subplots(2, 2, figsize=(14, 12))

# Elbow Method
axes[0, 0].plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)
axes[0, 0].axvline(x=optimal_k, color='r', linestyle='--', label=f'Optimal K = {optimal_k}')
axes[0, 0].set_xlabel('Number of Clusters (K)')
axes[0, 0].set_ylabel('Inertia')
axes[0, 0].set_title('Elbow Method for Optimal K', fontweight='bold')
axes[0, 0].legend()

# Silhouette Score
axes[0, 1].plot(K_range, silhouette_scores, 'go-', linewidth=2, markersize=8)
axes[0, 1].axvline(x=optimal_k, color='r', linestyle='--', label=f'Optimal K = {optimal_k}')
axes[0, 1].set_xlabel('Number of Clusters (K)')
axes[0, 1].set_ylabel('Silhouette Score')
axes[0, 1].set_title('Silhouette Score by K', fontweight='bold')
axes[0, 1].legend()

# Customer Segments Distribution
segment_counts = rfm['segment_name'].value_counts()
axes[1, 0].pie(segment_counts.values, labels=segment_counts.index, autopct='%1.1f%%',
               colors=COLORS[:len(segment_counts)], explode=[0.02]*len(segment_counts))
axes[1, 0].set_title('Customer Segment Distribution', fontweight='bold')

# RFM Scatter (Frequency vs Monetary)
scatter = axes[1, 1].scatter(rfm['frequency'], rfm['monetary'], 
                              c=rfm['cluster'], cmap='viridis', alpha=0.7, s=100)
axes[1, 1].set_xlabel('Frequency (# Orders)')
axes[1, 1].set_ylabel('Monetary (Total Sales $)')
axes[1, 1].set_title('Customer Segments: Frequency vs Monetary', fontweight='bold')
plt.colorbar(scatter, ax=axes[1, 1], label='Cluster')

plt.tight_layout()
plt.savefig(os.path.join(script_dir, 'ml_customer_segmentation.png'), dpi=300, bbox_inches='tight')
plt.close()
print("\n   âœ“ Saved: ml_customer_segmentation.png")

# Save customer segments
rfm.to_csv(os.path.join(script_dir, 'customer_segments.csv'), index=False)
print("   âœ“ Saved: customer_segments.csv")

# ============================================================
# MODEL 3: PROFIT CLASSIFICATION (Decision Tree)
# ============================================================
print("\n" + "=" * 70)
print("ğŸ“ˆ MODEL 3: PROFIT CLASSIFICATION (Decision Tree)")
print("=" * 70)

# Create profit categories
print("\nğŸ“Š Creating Profit Categories...")

df['profit_category'] = pd.cut(df['profit'], 
                                bins=[-np.inf, 0, 50, 200, np.inf],
                                labels=['Loss', 'Low', 'Medium', 'High'])

print(f"\n   Profit Category Distribution:")
print(df['profit_category'].value_counts())

# Prepare features
profit_features = df.copy()
profit_features['category_encoded'] = le_category.transform(profit_features['category'])
profit_features['segment_encoded'] = le_segment.transform(profit_features['segment'])
profit_features['region_encoded'] = le_region.transform(profit_features['region'])
profit_features['ship_mode_encoded'] = le_ship_mode.transform(profit_features['ship_mode'])
profit_features['sub_category_encoded'] = le_sub_category.transform(profit_features['sub_category'])

# Feature selection
profit_feature_cols = ['quantity', 'unit_price', 'discount', 'shipping_cost',
                       'category_encoded', 'segment_encoded', 'region_encoded',
                       'ship_mode_encoded', 'month', 'quarter']

X_profit = profit_features[profit_feature_cols]
y_profit = profit_features['profit_category']

# Encode target
le_profit = LabelEncoder()
y_profit_encoded = le_profit.fit_transform(y_profit)

# Split data
X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(
    X_profit, y_profit_encoded, test_size=0.2, random_state=42, stratify=y_profit_encoded
)

# Train Decision Tree
print("\nğŸ”§ Training Decision Tree Classifier...")
dt_model = DecisionTreeClassifier(max_depth=6, min_samples_split=20, random_state=42)
dt_model.fit(X_train_p, y_train_p)

# Predictions
y_pred_p = dt_model.predict(X_test_p)

# Metrics
accuracy = (y_pred_p == y_test_p).mean()
print(f"\n   âœ“ Accuracy: {accuracy:.4f}")

print("\nğŸ“Š Classification Report:")
print(classification_report(y_test_p, y_pred_p, target_names=le_profit.classes_))

# Confusion Matrix Visualization
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Confusion Matrix
cm = confusion_matrix(y_test_p, y_pred_p)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],
            xticklabels=le_profit.classes_, yticklabels=le_profit.classes_)
axes[0].set_xlabel('Predicted')
axes[0].set_ylabel('Actual')
axes[0].set_title('Confusion Matrix: Profit Classification', fontweight='bold')

# Feature Importance
dt_importance = pd.DataFrame({
    'Feature': profit_feature_cols,
    'Importance': dt_model.feature_importances_
}).sort_values('Importance', ascending=True)

axes[1].barh(dt_importance['Feature'], dt_importance['Importance'], color=COLORS[2])
axes[1].set_xlabel('Importance Score')
axes[1].set_title('Feature Importance (Decision Tree)', fontweight='bold')

plt.tight_layout()
plt.savefig(os.path.join(script_dir, 'ml_profit_classification.png'), dpi=300, bbox_inches='tight')
plt.close()
print("\n   âœ“ Saved: ml_profit_classification.png")

# ============================================================
# MODEL SUMMARY & INSIGHTS
# ============================================================
print("\n" + "=" * 70)
print("ğŸ“ ML MODEL SUMMARY")
print("=" * 70)

print(f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     MACHINE LEARNING RESULTS                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  ğŸ¯ MODEL 1: SALES PREDICTION                                        â”‚
â”‚     â€¢ Best Model: {best_model:<30}                              â”‚
â”‚     â€¢ RÂ² Score: {best_r2:.4f}                                        â”‚
â”‚     â€¢ Key Features: unit_price, quantity, discount                   â”‚
â”‚     â€¢ Use Case: Forecast sales for inventory planning                â”‚
â”‚                                                                      â”‚
â”‚  ğŸ‘¥ MODEL 2: CUSTOMER SEGMENTATION                                   â”‚
â”‚     â€¢ Algorithm: K-Means Clustering (K={optimal_k})                   â”‚
â”‚     â€¢ Silhouette Score: {max(silhouette_scores):.4f}                                â”‚
â”‚     â€¢ Segments Identified:                                           â”‚
""")

for seg, count in segment_counts.items():
    print(f"â”‚        - {seg}: {count} customers                              ")

print(f"""â”‚                                                                      â”‚
â”‚  ğŸ“ˆ MODEL 3: PROFIT CLASSIFICATION                                   â”‚
â”‚     â€¢ Algorithm: Decision Tree (max_depth=6)                         â”‚
â”‚     â€¢ Accuracy: {accuracy:.4f}                                          â”‚
â”‚     â€¢ Categories: Loss, Low, Medium, High profit                     â”‚
â”‚     â€¢ Key Insight: Discount is major factor affecting profitability  â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¡ BUSINESS RECOMMENDATIONS:

1. ğŸ“Š Sales Forecasting:
   - Use {best_model} model to predict sales
   - Focus on high unit_price products for revenue growth
   - Optimize quantity per order through bundling

2. ğŸ‘¥ Customer Strategy:
   - Champions: Reward with exclusive offers
   - At Risk: Re-engagement campaigns needed
   - Potential Loyalists: Upselling opportunities

3. ğŸ’° Profitability:
   - Limit discounts above 20% (causes losses)
   - Focus on Office Supplies (highest margin: 30%)
   - Review Technology pricing (lowest margin: 11.6%)
""")

# Save model summary
summary = {
    'Model': ['Sales Prediction', 'Customer Segmentation', 'Profit Classification'],
    'Algorithm': [best_model, f'K-Means (K={optimal_k})', 'Decision Tree'],
    'Performance': [f'RÂ²={best_r2:.4f}', f'Silhouette={max(silhouette_scores):.4f}', f'Accuracy={accuracy:.4f}'],
    'Key_Insight': [
        'Unit price is most important feature',
        f'{len(segment_counts)} customer segments identified',
        'Discount significantly impacts profit category'
    ]
}
pd.DataFrame(summary).to_csv(os.path.join(script_dir, 'ml_model_summary.csv'), index=False)
print("\n   âœ“ Saved: ml_model_summary.csv")

# Save models
models_dir = os.path.join(script_dir, 'saved_models')
os.makedirs(models_dir, exist_ok=True)

with open(os.path.join(models_dir, 'sales_predictor.pkl'), 'wb') as f:
    pickle.dump(results[best_model]['model'], f)
with open(os.path.join(models_dir, 'customer_segmentor.pkl'), 'wb') as f:
    pickle.dump(kmeans_final, f)
with open(os.path.join(models_dir, 'profit_classifier.pkl'), 'wb') as f:
    pickle.dump(dt_model, f)
with open(os.path.join(models_dir, 'scalers.pkl'), 'wb') as f:
    pickle.dump({'features': scaler, 'rfm': scaler_rfm}, f)

print("   âœ“ Saved trained models to: saved_models/")

print("\n" + "=" * 70)
print("âœ… ML MODELING COMPLETE!")
print("=" * 70)
print(f"""
ğŸ“ Output Files Generated:
   â€¢ ml_sales_prediction.png
   â€¢ ml_feature_importance.png
   â€¢ ml_customer_segmentation.png
   â€¢ ml_profit_classification.png
   â€¢ customer_segments.csv
   â€¢ ml_model_summary.csv
   â€¢ saved_models/sales_predictor.pkl
   â€¢ saved_models/customer_segmentor.pkl
   â€¢ saved_models/profit_classifier.pkl
   â€¢ saved_models/scalers.pkl
""")
